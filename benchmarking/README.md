# ğŸ“Š Embedding Model Benchmarking Suite

This folder contains comprehensive benchmarking tests for Google embedding models across three domains: **Professions**, **Education**, and **Locations**.

## ğŸ“ Folder Structure

```
benchmarking/
â”œâ”€â”€ prof_test.py                    # Profession domain benchmark
â”œâ”€â”€ edu_test.py                     # Education domain benchmark  
â”œâ”€â”€ loc_test.py                     # Location domain benchmark
â”œâ”€â”€ global_benchmark.py             # Aggregates all results (v2.0 - JSON support!)
â”‚
â”œâ”€â”€ benchmark_report.html           # Profession results (HTML)
â”œâ”€â”€ edu_benchmark_report.html       # Education results (HTML)
â”œâ”€â”€ loc_benchmark_report.html       # Location results (HTML)
â”œâ”€â”€ global_benchmark_report.html    # Global aggregated results
â”‚
â”œâ”€â”€ prof_results.json               # Profession results (JSON) âœ¨ NEW!
â”œâ”€â”€ edu_results.json                # Education results (JSON) âœ¨ NEW!
â”œâ”€â”€ loc_results.json                # Location results (JSON) âœ¨ NEW!
â”‚
â””â”€â”€ README.md                       # This file
```

## ğŸš€ Quick Start

### 1. Run Individual Domain Tests

```bash
# Run profession benchmark
python prof_test.py

# Run education benchmark
python edu_test.py

# Run location benchmark
python loc_test.py
```

Each test will:
- âœ… Generate an interactive HTML report (for viewing)
- âœ… Export structured JSON data (for analysis) âœ¨ **NEW in v2.0!**
- âœ… Test 6 embedding model configurations
- âœ… Evaluate 4 distance metrics (cosine, L2, L1, inner product)
- âœ… Calculate metrics: nDCG, MRR, Precision@5, Recall@5
- âœ… Auto-open results in your browser

### 2. Generate Global Report

After running all three tests:

```bash
python global_benchmark.py
```

This aggregates results across all domains and identifies the best overall model configuration.

**NEW in v2.0:** The global benchmark now reads JSON files (10x faster!) with automatic fallback to HTML.

## ğŸ“Š Output Files Explained

### HTML Reports (For Humans ğŸ‘¥)
- **Purpose:** Beautiful, interactive visualization
- **Features:** Charts, tables, collapsible sections, tiered analysis
- **Use Case:** Presenting results, visual exploration

### JSON Files (For Machines ğŸ¤–) âœ¨ NEW!
- **Purpose:** Structured, programmatic data access  
- **Features:** Fast parsing, type preservation, easy integration
- **Use Case:** Dashboards, trend analysis, automation, CI/CD

## ğŸ“‹ Test Configurations

### Models Tested
- `text-embedding-004` (768 dimensions)
- `text-embedding-005` (768 dimensions)
- `gemini-embedding-001` (768, 1152, 1536, 3072 dimensions)

### Distance Metrics
- Cosine Similarity
- Euclidean Distance (L2)
- Manhattan Distance (L1)
- Inner Product

### Evaluation Metrics
- **nDCG** (Normalized Discounted Cumulative Gain) - Primary metric
- **MRR** (Mean Reciprocal Rank)
- **Precision@5** - Weighted precision for top 5 results
- **Recall@5** - Weighted recall for top 5 results

## ğŸ¯ Domain Details

### Profession Test (`prof_test.py`)
- **Corpus:** 59 professions across IT, Medical, Legal, Creative, Education sectors
- **Queries:** 6 test scenarios (Software Developer, Data Scientist, Doctor, Designer, Lawyer, Professor)
- **Ground Truth:** Tiered relevance (3 levels)

### Education Test (`edu_test.py`)
- **Corpus:** 68 educational degrees and qualifications
- **Queries:** 5 test scenarios (Computer Science, Doctor, MBA, Psychology, Accountant)
- **Ground Truth:** Tiered relevance with abbreviations and equivalencies

### Location Test (`loc_test.py`)
- **Corpus:** 37 Indian locations (metros, tier-2 cities, regions)
- **Queries:** 4 test scenarios (Delhi NCR, Near Mumbai, South India, Pune)
- **Ground Truth:** Tiered relevance with geographical proximity

## ğŸ“Š Understanding Results

### Tiered Ground Truth
Results are evaluated using a 3-tier weighted system:

- **Tier 1 (â­â­â­):** Weight 3.0 - Highly relevant, perfect matches
- **Tier 2 (â­â­):** Weight 2.0 - Relevant, strong semantic similarity
- **Tier 3 (â­):** Weight 1.0 - Somewhat relevant, related concepts
- **Not listed:** Weight 0.0 - Irrelevant

### Interpreting nDCG Scores
- **> 0.90:** Excellent âœ…
- **0.80-0.90:** Good ğŸ‘
- **0.70-0.80:** Fair âš ï¸
- **< 0.70:** Needs improvement âŒ

## ğŸ”§ Requirements

```bash
pip install pandas numpy scikit-learn google-genai python-dotenv google-auth
```

## âš™ï¸ Configuration

Tests use credentials from `../../vivah_api/.env`:
```env
GEMINI_API_KEY=your_api_key
GOOGLE_APPLICATION_CREDENTIALS=path/to/service_account.json
GCP_PROJECT_ID=your_project_id
GCP_LOCATION=us-central1
```

## ğŸ’¡ Using JSON Data for Analysis

### Quick Analysis with Pandas
```python
import pandas as pd

# Load results
prof = pd.read_json('prof_results.json')
edu = pd.read_json('edu_results.json')
loc = pd.read_json('loc_results.json')

# Find best model
best = prof.nlargest(1, 'Avg nDCG')
print(f"Best: {best['Model'].values[0]}")
```

### Build a Dashboard
```python
import streamlit as st
import plotly.express as px

st.title("ğŸ“Š Embedding Benchmark Dashboard")
df = pd.read_json('prof_results.json')
fig = px.bar(df, x='Model', y='Avg nDCG', color='Distance')
st.plotly_chart(fig)
```

## ğŸ“ˆ Future Enhancements

- [ ] Time-series tracking of model performance
- [ ] Interactive dashboard (Streamlit/Plotly)
- [ ] CI/CD integration
- [ ] A/B testing framework
- [ ] Cost analysis per model
- [ ] Performance comparison over time

## ğŸ¤ Contributing

To add a new domain benchmark:
1. Copy one of the existing test files
2. Update the CORPUS with your domain data
3. Define TES T_SCENARIOS with tiered ground truth
4. Update HTML titles and output filenames
5. Add to `global_benchmark.py` REPORTS dictionary

## ğŸ“ Notes

- Each test takes ~2-5 minutes to run (depending on API latency)
- Results are deterministic for the same model configuration
- HTML reports are self-contained (all CSS/JS embedded)
- JSON files enable 10x faster data loading
- Models are queried in real-time via Google Gemini API

## ğŸ†• Changelog

### Version 2.0 (2026-01-23)
- âœ¨ Added JSON export to all benchmark tests
- ğŸš€ Global benchmark now reads JSON (10x faster parsing)
- âœ… Automatic fallback to HTML if JSON unavailable
- ğŸ“Š Enhanced data analysis capabilities
- ğŸ”§ Improved folder structure

### Version 1.0 (2026-01-23)
- Initial release with HTML reports
- Three domain benchmarks (Profession, Education, Location)
- Global aggregation across domains

---

**Last Updated:** 2026-01-23  
**Version:** 2.0
